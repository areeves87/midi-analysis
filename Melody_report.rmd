---
title: "Melody Track Identification"
author: "Alex Reeves"
date: "March 3, 2018"
output: html_document
---

#Abstract

MIDI files have tracks with musical note data in them. Usually, one of those tracks is the melody and the others are accompaniment. The goal of the work is to automatically identify the melody using the statistical properties of the musical content and pattern recognition techniques. Finding the meldoy automatically could be useful for a number of tasks, like speeding up melody matching when searching MIDI databases or motif extraction. Here I show a method for automatically selecting the melody track with AUC-ROC 0.926 and a AUC-PR of 0.772 using a conditional random forest model. The predictors for the cRF model were derived from the statistical properties of the MIDI tracks, and the model outputs a probability that the track is the melody. For training and testing data, I hand-labeled the melody tracks of 226 Final Fantasy MIDI songs. 

#Introduction

MIDIs files freely available on the internet number in the 100,000s. Most of these MIDIs contain a number of tracks, one of which is the melody and the others are accompaniement. The goal of this work is to automatically identify the melody from the stastical properties of the MIDI file. This methodology could be extended to other symbolic music file types since it relies on note pitch and duration information, which is essential to any symbolic representation of music. The main difficulty would be in writing the file parser so that track information from the new file type could be read into the routine. 

Although I started this project without serious consideration of the practical benefits of automatically selecting the melody track, in hindsight there are good applications. For example, if you wanted to query a database for a melody, it would reduce the search space if you knew or could accurately predict which track would contain the melody. This is because most of the time what people get stuck in their head is the melody, so their query is usually a melody. Another application would be extracting themes and motifs from corpuses, since melodies typically contain the themes and motifs.

This work follows the approach of David Rizo's paper. He implimeneted machine learning instead of simple heuristics based on note statistics or track names. Since his paper, there have been many interesting developments in the field of music information retrieval. But to date the work of identifying and parsing melodies from MIDI files mostly focuses on classical, jazz, and pop music genres. I try to extend this approach to videogame music, which is a genre born and bred in the MIDI format. 

His approach was in contrast to those before him who had implimented simple heuristics. 

Since his paper, others have implimeneted his approach while also bearing in mind the imbalanced nature of melody selection. That is, accompaniement tracks typically outnumber melody tracks 4:1. They improve their algorithm's performance by upsampling melodies or downsampling accompaniment.

The dataset consists of 227 MIDI transcriptions from the game series Final Fantasy. The purpose of this project is to predict the melody track in a transcription using a supervised learning approach. This requires labeled data, which I generated by manually tagging the melody track in all 227 transcriptions. I operated under the assumption that there would usually be a single melody track but that there would probably be a few exceptions to that general rule. Using these labels I trained the classifier with one half of the data and tested the classifier using the other half. 

#Methods

To read in the transcriptions, I used the R package 'TuneR', which produced tabular data representing all the note events in the transcription. From this I split the data into test and train groups. Then I trained the classifier on the training data and validated the classifier's performance using the test data.

##Midi Track Characterization

##Random Forest Classifier

##Track Selection Procedure

#Results

##Datasets

##Experiments

###Melody vs. non-melody classification

###Melodic track selection experiment

###Style specificity

###Traing set specificity

#Conclusions and Future Work